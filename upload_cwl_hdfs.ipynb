{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InsecureClient('http://namenode:50070', user='vagrant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.makedirs('/Users/vagrant/cwl-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datadir = os.path.join('/home/', 'vagrant/', 'work/' 'week7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local directories of interest\n",
    "directories = [\"structured-2018-07-29-proleague2/\",\n",
    "      \"structured-2018-08-19-champs/\",\n",
    "      \"structured-2018-04-08-proleague1/\",\n",
    "      \"structured-2018-04-19-relegation/\",\n",
    "      \"structured-2018-06-17-anaheim/\",\n",
    "      \"structured-2018-03-11-atlanta/\",\n",
    "      \"structured-2018-04-22-seattle/\",\n",
    "      \"structured-2018-04-01-birmingham/\",\n",
    "      \"structured-2018-01-14-neworleans/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of paths to local directories\n",
    "paths_to_data = []\n",
    "for i in range(0, len(directories)):\n",
    "    paths_to_data.append(os.path.join(datadir, directories[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of dirs for hdfs\n",
    "hdfs_dirs = []\n",
    "for i in range(0, len(paths_to_data)):\n",
    "    hdfs_dirs.append(os.path.join('/Users/vagrant/cwl-data/', directories[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dirs in hdfs\n",
    "for i in range(0, len(hdfs_dirs)):\n",
    "    client.makedirs(hdfs_dirs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['structured-2018-01-14-neworleans',\n",
       " 'structured-2018-03-11-atlanta',\n",
       " 'structured-2018-04-01-birmingham',\n",
       " 'structured-2018-04-08-proleague1',\n",
       " 'structured-2018-04-19-relegation',\n",
       " 'structured-2018-04-22-seattle',\n",
       " 'structured-2018-06-17-anaheim',\n",
       " 'structured-2018-07-29-proleague2',\n",
       " 'structured-2018-08-19-champs']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that hdfs directories were made\n",
    "client.list('/Users/vagrant/cwl-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 structured-2018-07-29-proleague2/\n",
      "296 structured-2018-08-19-champs/\n",
      "506 structured-2018-04-08-proleague1/\n",
      "39 structured-2018-04-19-relegation/\n",
      "270 structured-2018-06-17-anaheim/\n",
      "277 structured-2018-03-11-atlanta/\n",
      "272 structured-2018-04-22-seattle/\n",
      "164 structured-2018-04-01-birmingham/\n",
      "280 structured-2018-01-14-neworleans/\n"
     ]
    }
   ],
   "source": [
    "# get local directory sizes\n",
    "dir_sizes = []\n",
    "for i in range(0, len(paths_to_data)):\n",
    "    dir_sizes.append(len(os.listdir(paths_to_data[i])))\n",
    "    \n",
    "# local paths\n",
    "local_json_paths = []    \n",
    "for i in range(0, len(paths_to_data)):\n",
    "    for j in range(0, dir_sizes[i]):\n",
    "        local_json_paths.append(os.path.join(paths_to_data[i], os.listdir(paths_to_data[i])[j]))\n",
    "\n",
    "# visualize directories and their sizes        \n",
    "for i in range(0, len(directories)):\n",
    "    print(dir_sizes[i], directories[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths in hdfs\n",
    "hdfs_json_paths = []\n",
    "for i in range(0, len(hdfs_dirs)):\n",
    "    for j in range(0, dir_sizes[i]):\n",
    "        hdfs_json_paths.append(os.path.join(hdfs_dirs[i], os.listdir(paths_to_data[i])[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload jsons to hdfs, the try/except handles uploading in various steps\n",
    "for i in range(0, len(local_json_paths)):\n",
    "    try:\n",
    "        client.upload(hdfs_json_paths[i], local_json_paths[i])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "# check that appropriate number of json files were uploaded\n",
    "for i in range(0, len(hdfs_dirs)):\n",
    "    if len(client.list(hdfs_dirs[i])) - dir_sizes[i] == 0:\n",
    "        print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
