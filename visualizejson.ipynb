{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python processing of JSON files to build visualizations using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to maps and map image dictionary\n",
    "PATH_TO_WW2_MAPS = '../week6/cwl-data/maps/ww2/'\n",
    "\n",
    "MAP_IMAGES = {\n",
    "    'Aachen': 'aachen.png',\n",
    "    'Ardennes Forest': 'ardennes_forest.png',\n",
    "    'Flak Tower': 'flaktower.png',\n",
    "    'Gibraltar': 'gibraltar.png',\n",
    "    'London Docks': 'london_docks.png',\n",
    "    'Sainte Marie du Mont': 'sainte_marie_du_mont.png' ,\n",
    "    'USS Texas': 'uss_texas.png',\n",
    "    'Valkyrie': 'valkyrie.png'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of events\n",
    "pattern = re.compile(r'structured-2018')\n",
    "event_list = list(filter(pattern.match, os.listdir(\"./\")))\n",
    "#event_list\n",
    "\n",
    "# dictionary of events and list of matches given an event\n",
    "# {event:[match list]}\n",
    "dict_event_matches = {}\n",
    "for i in range(0, len(event_list)):\n",
    "    dict_event_matches.update({event_list[i]: os.listdir('./{}'.format(event_list[i]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for PNG plots\n",
    "PATH_TO_PICS = './png_plots/'\n",
    "\n",
    "if not os.path.exists(PATH_TO_PICS):\n",
    "    os.makedirs(PATH_TO_PICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 :  structured-2018-07-29-proleague2\n",
      "296 :  structured-2018-08-19-champs\n",
      "506 :  structured-2018-04-08-proleague1\n",
      "39 :  structured-2018-04-19-relegation\n",
      "270 :  structured-2018-06-17-anaheim\n",
      "277 :  structured-2018-03-11-atlanta\n",
      "272 :  structured-2018-04-22-seattle\n",
      "164 :  structured-2018-04-01-birmingham\n",
      "280 :  structured-2018-01-14-neworleans\n"
     ]
    }
   ],
   "source": [
    "# checked with ls | wc -l and number of jsons check out\n",
    "for i in dict_event_matches:\n",
    "    print(len(dict_event_matches[str(i)]), ': ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2612"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_files = []\n",
    "for EVENT in dict_event_matches:\n",
    "    for MATCH in dict_event_matches[str(EVENT)]:\n",
    "        match_files.append('{}/{}'.format(EVENT, MATCH))\n",
    "    \n",
    "len(match_files) # 2612 == correct\n",
    "#match_files[1] # a json file for the match\n",
    "#os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n"
     ]
    }
   ],
   "source": [
    "# GIGANTIC LOOP for plotting 2612 plots in respective directories\n",
    "\n",
    "# load match data and save a PNG of match actions\n",
    "\n",
    "for i in range(0, len(match_files)):\n",
    "    \n",
    "    # assess progress of loop\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    with open(match_files[i], 'r') as match_file:\n",
    "        \n",
    "        # get match data\n",
    "        match = json.load(match_file)\n",
    "\n",
    "        dirname, figname = match_files[i].split('.')[0].split('/')\n",
    "\n",
    "        # make new directory for PNGs for a particular event\n",
    "        newdir = os.path.join(PATH_TO_PICS, dirname)\n",
    "\n",
    "        if not os.path.exists(newdir):\n",
    "            os.makedirs(newdir)\n",
    "\n",
    "        # create name of PNG\n",
    "        FIGURE_NAME = figname + str('.png')\n",
    "\n",
    "        # get position data\n",
    "        death_pos, spawn_pos = {'x': [], 'y': []}, {'x': [], 'y': []}\n",
    "        events = match['events']\n",
    "        for evt in events:\n",
    "            if evt['type'] == 'spawn':\n",
    "                spawn_pos['x'].append( evt['data']['pos']['x'] )\n",
    "                spawn_pos['y'].append( evt['data']['pos']['y'] )\n",
    "            if evt['type'] == 'death':\n",
    "                death_pos['x'].append( evt['data']['pos']['x'] )\n",
    "                death_pos['y'].append( evt['data']['pos']['y'] )\n",
    "\n",
    "        # get map image\n",
    "        # account for KeyError: '?' (mislabelled maps)\n",
    "        try:\n",
    "            map_file_name = PATH_TO_WW2_MAPS + MAP_IMAGES[match['map']]\n",
    "            map_image = mpimg.imread(map_file_name)\n",
    "        except KeyError:\n",
    "            map_image = 'Unknown Location'\n",
    "        \n",
    "        # create figure\n",
    "        fig = Figure()\n",
    "        FigureCanvas(fig)\n",
    "        ax = fig.add_subplot(111)\n",
    "        fig.set_figheight(15)\n",
    "        fig.set_figwidth(15)\n",
    "\n",
    "        # plot map\n",
    "        try:\n",
    "            ax.imshow(map_image)\n",
    "            ax.set_facecolor((180/255.0, 200/255.0, 220/255.0))\n",
    "        except TypeError:\n",
    "            pass\n",
    "        \n",
    "        # plot spawns\n",
    "        ax.scatter(spawn_pos['x'], spawn_pos['y'], color='blue')\n",
    "        \n",
    "        # plot deaths\n",
    "        ax.scatter(death_pos['x'], death_pos['y'], color='red')\n",
    "        \n",
    "        # plot spawn-death vectors\n",
    "        for i in range( len(death_pos['x']) ):\n",
    "            ax.plot([spawn_pos['x'][i], death_pos['x'][i]], \n",
    "                     [spawn_pos['y'][i], death_pos['y'][i]], color='dimgrey')\n",
    "        # set title\n",
    "        ax.set_title('{} ({})'.format(match['map'], match['mode']))\n",
    "\n",
    "        # save as png\n",
    "        fig.savefig('{}/{}'.format(newdir, FIGURE_NAME))\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
